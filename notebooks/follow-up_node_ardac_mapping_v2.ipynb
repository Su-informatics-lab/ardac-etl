{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c8dd67-1d1b-4538-9149-a01c5ec64e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bc01a3-804b-41cf-ad2e-0f29d4194c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the template TSV file containing the headers\n",
    "template_file_path = \"node_template/submission_follow_up_template.tsv\"\n",
    "\n",
    "# Read the template TSV file to extract the headers\n",
    "df_template = pd.read_csv(template_file_path, sep=\"\\t\", nrows=0)  # Read only the header\n",
    "headers = df_template.columns.tolist()  # Extract the headers as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81acf932-89c0-42b8-afc1-2021c0cf4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observational Patients\n",
    "# File paths\n",
    "case_path_obs = \"/Users/jinn/Documents/IU/ARDaC/case_obs_DCC_data_release_v2-0-0.tsv\"\n",
    "\n",
    "# Read the files using pandas\n",
    "df_obs_case = pd.read_csv(case_path_obs, sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract \"*submitter_id\" from df_obs_case and create case_table\n",
    "case_table = pd.DataFrame()\n",
    "case_table[\"*submitter_id\"] = df_obs_case[\"*submitter_id\"]\n",
    "case_table[\"usubjid\"] = case_table[\"*submitter_id\"].apply(lambda x: x.split(\"_\")[0])  # Extract the number before \"_\"\n",
    "\n",
    "# Initialize the output DataFrame with the headers\n",
    "df_output = pd.DataFrame(columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676971c4-ed9a-49a7-99bd-40d701d9a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "enerating Follow-up Rows: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1134/1134 [04:49<00:00,  3.92it/s]"
     ]
    }
   ],
   "source": [
    "# Define the extensions for mapping\n",
    "extensions = {\"Week 0\": \"_0\", \"Week 4\": \"_28\", \"Week 12\": \"_84\", \"Week 24\": \"_168\"}\n",
    "\n",
    "for _, row in tqdm(case_table.iterrows(), total=len(case_table), desc=\"Generating OBS Follow-up Rows\"):\n",
    "    submitter_id = row[\"*submitter_id\"]\n",
    "\n",
    "    for week, ext in extensions.items():\n",
    "        new_row = {\n",
    "            \"*type\": \"follow_up\",\n",
    "            \"project_id\": \"ARDaC-AlcHepNet\",\n",
    "            \"*submitter_id\": f\"{submitter_id}{ext}\",\n",
    "            \"cases.submitter_id\": submitter_id,\n",
    "            \"demographics.submitter_id\": f\"{submitter_id}_demographic\",\n",
    "            \"*days_to_follow_up\": ext.lstrip(\"_\"),  # Remove \"_\" from the extension\n",
    "            \"visit_day\": ext.lstrip(\"_\")\n",
    "        }\n",
    "        df_output = pd.concat([df_output, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fef240e-7a46-43b9-aef5-b12ccaa91953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing Liver Scores: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 2642/2642 [00:01<00:00, 1687.37it/s]"
     ]
    }
   ],
   "source": [
    "# OBS_LIVERSCORES\n",
    "# Path to the liver scores file\n",
    "liver_scores_path = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/OBS Final Datasets/OBS_LIVERSCORES.csv\"\n",
    "df_liver_scores = pd.read_csv(liver_scores_path, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the liver scores and map values to follow-up rows\n",
    "for _, row in tqdm(df_liver_scores.iterrows(), total=len(df_liver_scores), desc=\"Processing Liver Scores\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid weeks\n",
    "    if redcap_event_name not in extensions:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_obs{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output[df_output[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output.loc[output_row_index, \"meld_score\"] = row.get(\"meld\", None)\n",
    "        df_output.loc[output_row_index, \"child_pugh_score\"] = row.get(\"cps\", None)\n",
    "        df_output.loc[output_row_index, \"tlfb_drinking_days\"] = row.get(\"tlfbnumdd\", None)\n",
    "        df_output.loc[output_row_index, \"tlfb_number_drinks\"] = row.get(\"tlfbnumd\", None)\n",
    "        df_output.loc[output_row_index, \"liver_score_date\"] = row.get(\"liverdat\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2277fbc-0d1e-466b-878f-41e1a89ba636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing MedInfo: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1878/1878 [00:02<00:00, 892.74it/s]"
     ]
    }
   ],
   "source": [
    "# OBS_MEDINFO\n",
    "# Path to the liver scores file\n",
    "med_info_path = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/OBS Final Datasets/OBS_MEDINFO.csv\"\n",
    "df_med_info = pd.read_csv(med_info_path, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the medinfo and map values to follow-up rows\n",
    "for _, row in tqdm(df_med_info.iterrows(), total=len(df_med_info), desc=\"Processing MedInfo\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid weeks\n",
    "    if redcap_event_name not in extensions:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_obs{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output[df_output[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output.loc[output_row_index, \"ascites_culture\"] = row.get(\"ascyn\", None)\n",
    "        df_output.loc[output_row_index, \"hep_enceph\"] = row.get(\"hepenyn\", None)\n",
    "        df_output.loc[output_row_index, \"varices\"] = row.get(\"varyn\", None)\n",
    "        df_output.loc[output_row_index, \"hep_carcinoma\"] = row.get(\"hepcaryn\", None)\n",
    "        df_output.loc[output_row_index, \"liver_transplant\"] = row.get(\"livtnsplyn\", None)\n",
    "        df_output.loc[output_row_index, \"ascites_date\"] = row.get(\"ascdat\", None)\n",
    "        df_output.loc[output_row_index, \"hep_enceph_diagnosis_date\"] = row.get(\"hependat\", None)\n",
    "        df_output.loc[output_row_index, \"varices_diagnosis_date\"] = row.get(\"vardat\", None)\n",
    "        df_output.loc[output_row_index, \"hepcar_diagnosis_date\"] = row.get(\"hepcardat\", None)\n",
    "        df_output.loc[output_row_index, \"liver_transplant_date\"] = row.get(\"livtnspldat\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d433f51a-7bf3-4fda-b22f-1eb6b05fc9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing Vitals: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1829/1829 [00:00<00:00, 2507.56it/s]"
     ]
    }
   ],
   "source": [
    "# OBS_VITALS\n",
    "\n",
    "# Path to the vitals file\n",
    "vitals_path = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/OBS Final Datasets/OBS_VITALS.csv\"\n",
    "df_vitals = pd.read_csv(vitals_path, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the medinfo and map values to follow-up rows\n",
    "for _, row in tqdm(df_vitals.iterrows(), total=len(df_vitals), desc=\"Processing Vitals\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid weeks\n",
    "    if redcap_event_name not in extensions:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_obs{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output[df_output[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output.loc[output_row_index, \"weight\"] = row.get(\"weight\", None)\n",
    "        df_output.loc[output_row_index, \"bmi\"] = row.get(\"bmi\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c53ca8b-57f4-45ba-b2cb-27708e9986f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing SOC: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1382/1382 [00:03<00:00, 368.38it/s]"
     ]
    }
   ],
   "source": [
    "# OBS_SOC\n",
    "\n",
    "# Path to the SOC file\n",
    "soc_path = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/OBS Final Datasets/OBS_SOC.csv\"\n",
    "df_soc = pd.read_csv(soc_path, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the medinfo and map values to follow-up rows\n",
    "for _, row in tqdm(df_soc.iterrows(), total=len(df_soc), desc=\"Processing SOC\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid weeks\n",
    "    if redcap_event_name not in extensions:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_obs{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output[df_output[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output.loc[output_row_index, \"infection_screen_done\"] = row.get(\"infscreennd\", None)\n",
    "        df_output.loc[output_row_index, \"infection_screen_date\"] = row.get(\"infscreen_date\", None)\n",
    "        df_output.loc[output_row_index, \"blood_culture\"] = row.get(\"socisbcnd___999\", None)\n",
    "        df_output.loc[output_row_index, \"blood_culture_result\"] = row.get(\"socisbc\", None)\n",
    "        df_output.loc[output_row_index, \"blood_organism\"] = row.get(\"socisbc_pos\", None)\n",
    "        df_output.loc[output_row_index, \"blood_culture_date\"] = row.get(\"socisbcdat\", None)\n",
    "        df_output.loc[output_row_index, \"urine_culture\"] = row.get(\"socisucnd___999\", None)\n",
    "        df_output.loc[output_row_index, \"urine_culture_result\"] = row.get(\"socisuc\", None)\n",
    "        df_output.loc[output_row_index, \"urine_culture_organism\"] = row.get(\"socisuc_pos\", None)\n",
    "        df_output.loc[output_row_index, \"urine_culture_date\"] = row.get(\"socisucdat\", None)\n",
    "        df_output.loc[output_row_index, \"urine_culture_fungal_result\"] = row.get(\"soicuc_fung\", None)\n",
    "        df_output.loc[output_row_index, \"ascites_culture\"] = row.get(\"socisacnd___999\", None)\n",
    "        df_output.loc[output_row_index, \"ascites_culture_result\"] = row.get(\"socisac\", None)\n",
    "        df_output.loc[output_row_index, \"ascites_organism\"] = row.get(\"socisac_pos\", None)\n",
    "        df_output.loc[output_row_index, \"ascites_date\"] = row.get(\"socisacdat\", None)\n",
    "        df_output.loc[output_row_index, \"endoscopy\"] = row.get(\"endond\", None)\n",
    "        df_output.loc[output_row_index, \"endoscopy_date\"] = row.get(\"endodat\", None)\n",
    "        df_output.loc[output_row_index, \"esophageal_varices_size\"] = row.get(\"endovarsiz_esoph\", None)\n",
    "        df_output.loc[output_row_index, \"esophageal_varices_bleed\"] = row.get(\"endobled_esoph\", None)\n",
    "        df_output.loc[output_row_index, \"gastric_varices_size\"] = row.get(\"endovarsiz_gast\", None)\n",
    "        df_output.loc[output_row_index, \"gastric_varices_bleed\"] = row.get(\"endobled_gast\", None)\n",
    "        df_output.loc[output_row_index, \"portal_hypertensive_gastropathy\"] = row.get(\"porthypsev\", None)\n",
    "        df_output.loc[output_row_index, \"esophageal_ulcer_size\"] = row.get(\"endoulcsiz_esoph\", None)\n",
    "        df_output.loc[output_row_index, \"esophageal_ulcer_bleed\"] = row.get(\"endoulcbled_esoph\", None)\n",
    "        df_output.loc[output_row_index, \"gastric_ulcer_size\"] = row.get(\"endoulcsiz_gast\", None)\n",
    "        df_output.loc[output_row_index, \"gastric_ulcer_bleed\"] = row.get(\"endoulcbled_gast\", None)\n",
    "        df_output.loc[output_row_index, \"duodenum_ulcer_size\"] = row.get(\"endoulcsiz_duod\", None)\n",
    "        df_output.loc[output_row_index, \"duodenum_ulcer_bleed\"] = row.get(\"endoulcbled_duod\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1068d7-a027-4bea-ba80-9dd4f71c6103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned follow-up table saved as: follow-up_obs_DCC_data_release_v2-0-0.tsv\n",
      "QC table saved as: follow-up_qc_obs_DCC_data_release_v2-0-0.tsv\n"
     ]
    }
   ],
   "source": [
    "# Final check: Remove empty rows and log them in a QC file\n",
    "qc_records = []  # To store QC information for deleted rows\n",
    "\n",
    "# Columns that define a row as \"non-empty\" (exclude the fixed columns)\n",
    "non_empty_columns = list(set(df_output.columns) - {\n",
    "    \"*type\", \"project_id\", \"*submitter_id\", \"cases.submitter_id\",\n",
    "    \"demographics.submitter_id\", \"*days_to_follow_up\", \"visit_day\"\n",
    "})\n",
    "\n",
    "# Iterate over df_output rows to identify empty rows\n",
    "for index, row in df_output.iterrows():\n",
    "    # Check if all non-fixed columns are empty\n",
    "    if row[non_empty_columns].isnull().all():\n",
    "        # Record the QC information\n",
    "        qc_records.append({\n",
    "            \"usubjid\": row[\"cases.submitter_id\"].split(\"_\")[0],  # Extract usubjid\n",
    "            \"*submitter_id\": row[\"*submitter_id\"],\n",
    "            \"empty_follow-up\": \"Y\"\n",
    "        })\n",
    "        # Drop the empty row\n",
    "        df_output.drop(index, inplace=True)\n",
    "\n",
    "# Save the QC records to a TSV file\n",
    "qc_output_path = \"follow-up_qc_obs_DCC_data_release_v2-0-0.tsv\"\n",
    "df_qc = pd.DataFrame(qc_records)\n",
    "df_qc.to_csv(qc_output_path, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "# Save the cleaned df_output to a TSV file\n",
    "output_path = \"follow-up_obs_DCC_data_release_v2-0-0.tsv\"\n",
    "df_output.to_csv(output_path, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "print(f\"Cleaned follow-up table saved as: {output_path}\")\n",
    "print(f\"QC table saved as: {qc_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d099562b-0d3b-4bde-be19-15f1178e16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical Patients\n",
    "# File paths\n",
    "case_path_rct = \"/Users/jinn/Documents/IU/ARDaC/case_rct_DCC_data_release_v2-0-0.tsv\"\n",
    "\n",
    "# Read the files using pandas\n",
    "df_rct_case = pd.read_csv(case_path_rct, sep=\"\\t\", dtype=str)\n",
    "\n",
    "# Extract \"*submitter_id\" from df_obs_case and create case_table\n",
    "case_table_rct = pd.DataFrame()\n",
    "case_table_rct[\"*submitter_id\"] = df_rct_case[\"*submitter_id\"]\n",
    "case_table_rct[\"usubjid\"] = case_table_rct[\"*submitter_id\"].apply(lambda x: x.split(\"_\")[0])  # Extract the number before \"_\"\n",
    "\n",
    "# Initialize the output DataFrame with the headers\n",
    "df_output_rct = pd.DataFrame(columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bc8a68e-7388-4c81-8226-99a5f417c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "enerating RCT Follow-up Rows: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [00:19<00:00,  7.43it/s]"
     ]
    }
   ],
   "source": [
    "# Define the extensions for mapping\n",
    "extensions_rct = {\"Day 0\": \"_0\", \"Day 3\": \"_3\", \"Day 7\": \"_7\", \"Day 14\": \"_14\", \"Day 28\": \"_28\",\"Day 60\": \"_60\",\"Day 90\": \"_90\", \"Day 180\": \"_180\"}\n",
    "\n",
    "for _, row in tqdm(case_table_rct.iterrows(), total=len(case_table_rct), desc=\"Generating RCT Follow-up Rows\"):\n",
    "    submitter_id = row[\"*submitter_id\"]\n",
    "\n",
    "    for day, ext in extensions_rct.items():\n",
    "        new_row = {\n",
    "            \"*type\": \"follow_up\",\n",
    "            \"project_id\": \"ARDaC-AlcHepNet\",\n",
    "            \"*submitter_id\": f\"{submitter_id}{ext}\",\n",
    "            \"cases.submitter_id\": submitter_id,\n",
    "            \"demographics.submitter_id\": f\"{submitter_id}_demographic\",\n",
    "            \"*days_to_follow_up\": ext.lstrip(\"_\"),  # Remove \"_\" from the extension\n",
    "            \"visit_day\": ext.lstrip(\"_\")\n",
    "        }\n",
    "        df_output_rct = pd.concat([df_output_rct, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1d4bb5-472e-4997-87e0-1ee91a4ef984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing RCT Liver Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 870/870 [00:00<00:00, 2120.55it/s]"
     ]
    }
   ],
   "source": [
    "# RCT_LIVERSCORES\n",
    "# Path to the liver scores file\n",
    "liver_scores_path_rct = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/RCT Final Datasets/RCT_LIVERSCORES.csv\"\n",
    "df_liver_scores_rct = pd.read_csv(liver_scores_path_rct, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the liver scores and map values to follow-up rows\n",
    "for _, row in tqdm(df_liver_scores_rct.iterrows(), total=len(df_liver_scores_rct), desc=\"Processing RCT Liver Scores\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid Days\n",
    "    if redcap_event_name not in extensions_rct:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions_rct[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_clinical{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output_rct[df_output_rct[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output_rct.loc[output_row_index, \"meld_score\"] = row.get(\"meld\", None)\n",
    "        df_output_rct.loc[output_row_index, \"child_pugh_score\"] = row.get(\"cps\", None)\n",
    "        df_output_rct.loc[output_row_index, \"tlfb_drinking_days\"] = row.get(\"tlfbnumdd\", None)\n",
    "        df_output_rct.loc[output_row_index, \"tlfb_number_drinks\"] = row.get(\"tlfbnumd\", None)\n",
    "        df_output_rct.loc[output_row_index, \"liver_score_date\"] = row.get(\"liverdat\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a35c0fc-ed93-44f2-b904-57cc0fb6d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RCT_MEDINFO\n",
    "# # Path to the liver scores file\n",
    "# med_info_path_rct = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/RCT Final Datasets/OBS_MEDINFO.csv\"\n",
    "# df_med_info = pd.read_csv(med_info_path, sep=\",\", dtype=str)\n",
    "\n",
    "# # Process the medinfo and map values to follow-up rows\n",
    "# for _, row in tqdm(df_med_info.iterrows(), total=len(df_med_info), desc=\"Processing MedInfo\"):\n",
    "#     usubjid = row[\"usubjid\"]\n",
    "#     redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "#     # Only process rows with valid weeks\n",
    "#     if redcap_event_name not in extensions_rct:\n",
    "#         continue\n",
    "\n",
    "#     # Convert redcap_event_name to the extension\n",
    "#     extension = extensions_rct[redcap_event_name]\n",
    "#     submitter_id = f\"{usubjid}_clinical{extension}\"\n",
    "\n",
    "#     # Find the matching row in df_output\n",
    "#     output_row_index = df_output[df_output[\"*submitter_id\"] == submitter_id].index\n",
    "#     if not output_row_index.empty:\n",
    "#         # Perform the mapping\n",
    "#         output_row_index = output_row_index[0]  # Get the first matching index\n",
    "#         df_output.loc[output_row_index, \"ascites_culture\"] = row.get(\"ascyn\", None)\n",
    "#         df_output.loc[output_row_index, \"hep_enceph\"] = row.get(\"hepenyn\", None)\n",
    "#         df_output.loc[output_row_index, \"varices\"] = row.get(\"varyn\", None)\n",
    "#         df_output.loc[output_row_index, \"hep_carcinoma\"] = row.get(\"hepcaryn\", None)\n",
    "#         df_output.loc[output_row_index, \"liver_transplant\"] = row.get(\"livtnsplyn\", None)\n",
    "#         df_output.loc[output_row_index, \"ascites_date\"] = row.get(\"ascdat\", None)\n",
    "#         df_output.loc[output_row_index, \"hep_enceph_diagnosis_date\"] = row.get(\"hependat\", None)\n",
    "#         df_output.loc[output_row_index, \"varices_diagnosis_date\"] = row.get(\"vardat\", None)\n",
    "#         df_output.loc[output_row_index, \"hepcar_diagnosis_date\"] = row.get(\"hepcardat\", None)\n",
    "#         df_output.loc[output_row_index, \"liver_transplant_date\"] = row.get(\"livtnspldat\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e9cf0ff-60f8-4c17-8c02-2bbfd362e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing RCT Vitals: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 817/817 [00:00<00:00, 3677.95it/s]"
     ]
    }
   ],
   "source": [
    "# RCT_VITALS\n",
    "\n",
    "# Path to the vitals file\n",
    "vitals_path_rct = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/RCT Final Datasets/RCT_VITALS.csv\"\n",
    "df_vitals_rct = pd.read_csv(vitals_path_rct, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the medinfo and map values to follow-up rows\n",
    "for _, row in tqdm(df_vitals_rct.iterrows(), total=len(df_vitals_rct), desc=\"Processing RCT Vitals\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid weeks\n",
    "    if redcap_event_name not in extensions_rct:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions_rct[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_clinical{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output_rct[df_output_rct[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output_rct.loc[output_row_index, \"weight\"] = row.get(\"weight\", None)\n",
    "        df_output_rct.loc[output_row_index, \"bmi\"] = row.get(\"bmi\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "362a861f-5b64-4f53-a308-85fc3d663388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "rocessing RCT SOC: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 429/429 [00:00<00:00, 527.21it/s]"
     ]
    }
   ],
   "source": [
    "# RCT_SOC\n",
    "\n",
    "# Path to the SOC file\n",
    "soc_path_rct = \"/Users/jinn/Documents/IU/ARDaC/DCC_data_release_v2.0.0/raw_data/Data for Nanxin/RCT Final Datasets/RCT_SOC.csv\"\n",
    "df_soc_rct = pd.read_csv(soc_path_rct, sep=\",\", dtype=str)\n",
    "\n",
    "# Process the medinfo and map values to follow-up rows\n",
    "for _, row in tqdm(df_soc_rct.iterrows(), total=len(df_soc_rct), desc=\"Processing RCT SOC\"):\n",
    "    usubjid = row[\"usubjid\"]\n",
    "    redcap_event_name = row[\"redcap_event_name\"]\n",
    "\n",
    "    # Only process rows with valid weeks\n",
    "    if redcap_event_name not in extensions_rct:\n",
    "        continue\n",
    "\n",
    "    # Convert redcap_event_name to the extension\n",
    "    extension = extensions_rct[redcap_event_name]\n",
    "    submitter_id = f\"{usubjid}_clinical{extension}\"\n",
    "\n",
    "    # Find the matching row in df_output\n",
    "    output_row_index = df_output_rct[df_output_rct[\"*submitter_id\"] == submitter_id].index\n",
    "    if not output_row_index.empty:\n",
    "        # Perform the mapping\n",
    "        output_row_index = output_row_index[0]  # Get the first matching index\n",
    "        df_output_rct.loc[output_row_index, \"infection_screen_done\"] = row.get(\"infscreennd\", None)\n",
    "        df_output_rct.loc[output_row_index, \"infection_screen_date\"] = row.get(\"infscreen_date\", None)\n",
    "        df_output_rct.loc[output_row_index, \"blood_culture\"] = row.get(\"socisbcnd___999\", None)\n",
    "        df_output_rct.loc[output_row_index, \"blood_culture_result\"] = row.get(\"socisbc\", None)\n",
    "        df_output_rct.loc[output_row_index, \"blood_organism\"] = row.get(\"socisbc_pos\", None)\n",
    "        df_output_rct.loc[output_row_index, \"blood_culture_date\"] = row.get(\"socisbcdat\", None)\n",
    "        df_output_rct.loc[output_row_index, \"urine_culture\"] = row.get(\"socisucnd___999\", None)\n",
    "        df_output_rct.loc[output_row_index, \"urine_culture_result\"] = row.get(\"socisuc\", None)\n",
    "        df_output_rct.loc[output_row_index, \"urine_culture_organism\"] = row.get(\"socisuc_pos\", None)\n",
    "        df_output_rct.loc[output_row_index, \"urine_culture_date\"] = row.get(\"socisucdat\", None)\n",
    "        df_output_rct.loc[output_row_index, \"urine_culture_fungal_result\"] = row.get(\"soicuc_fung\", None)\n",
    "        df_output_rct.loc[output_row_index, \"ascites_culture\"] = row.get(\"socisacnd___999\", None)\n",
    "        df_output_rct.loc[output_row_index, \"ascites_culture_result\"] = row.get(\"socisac\", None)\n",
    "        df_output_rct.loc[output_row_index, \"ascites_organism\"] = row.get(\"socisac_pos\", None)\n",
    "        df_output_rct.loc[output_row_index, \"ascites_date\"] = row.get(\"socisacdat\", None)\n",
    "        df_output_rct.loc[output_row_index, \"endoscopy\"] = row.get(\"endond\", None)\n",
    "        df_output_rct.loc[output_row_index, \"endoscopy_date\"] = row.get(\"endodat\", None)\n",
    "        df_output_rct.loc[output_row_index, \"esophageal_varices_size\"] = row.get(\"endovarsiz_esoph\", None)\n",
    "        df_output_rct.loc[output_row_index, \"esophageal_varices_bleed\"] = row.get(\"endobled_esoph\", None)\n",
    "        df_output_rct.loc[output_row_index, \"gastric_varices_size\"] = row.get(\"endovarsiz_gast\", None)\n",
    "        df_output_rct.loc[output_row_index, \"gastric_varices_bleed\"] = row.get(\"endobled_gast\", None)\n",
    "        df_output_rct.loc[output_row_index, \"portal_hypertensive_gastropathy\"] = row.get(\"porthypsev\", None)\n",
    "        df_output_rct.loc[output_row_index, \"esophageal_ulcer_size\"] = row.get(\"endoulcsiz_esoph\", None)\n",
    "        df_output_rct.loc[output_row_index, \"esophageal_ulcer_bleed\"] = row.get(\"endoulcbled_esoph\", None)\n",
    "        df_output_rct.loc[output_row_index, \"gastric_ulcer_size\"] = row.get(\"endoulcsiz_gast\", None)\n",
    "        df_output_rct.loc[output_row_index, \"gastric_ulcer_bleed\"] = row.get(\"endoulcbled_gast\", None)\n",
    "        df_output_rct.loc[output_row_index, \"duodenum_ulcer_size\"] = row.get(\"endoulcsiz_duod\", None)\n",
    "        df_output_rct.loc[output_row_index, \"duodenum_ulcer_bleed\"] = row.get(\"endoulcbled_duod\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "095896da-96fd-47a9-9117-a5af7a6a499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned RCT follow-up table saved as: follow-up_rct_DCC_data_release_v2-0-0.tsv\n",
      "RCT QC table saved as: follow-up_qc_rct_DCC_data_release_v2-0-0.tsv\n"
     ]
    }
   ],
   "source": [
    "# Final check: Remove empty rows and log them in a QC file\n",
    "qc_records_rct = []  # To store QC information for deleted rows\n",
    "\n",
    "# Columns that define a row as \"non-empty\" (exclude the fixed columns)\n",
    "non_empty_columns = list(set(df_output_rct.columns) - {\n",
    "    \"*type\", \"project_id\", \"*submitter_id\", \"cases.submitter_id\",\n",
    "    \"demographics.submitter_id\", \"*days_to_follow_up\", \"visit_day\"\n",
    "})\n",
    "\n",
    "# Iterate over df_output rows to identify empty rows\n",
    "for index, row in df_output_rct.iterrows():\n",
    "    # Check if all non-fixed columns are empty\n",
    "    if row[non_empty_columns].isnull().all():\n",
    "        # Record the QC information\n",
    "        qc_records_rct.append({\n",
    "            \"usubjid\": row[\"cases.submitter_id\"].split(\"_\")[0],  # Extract usubjid\n",
    "            \"*submitter_id\": row[\"*submitter_id\"],\n",
    "            \"empty_follow-up\": \"Y\"\n",
    "        })\n",
    "        # Drop the empty row\n",
    "        df_output_rct.drop(index, inplace=True)\n",
    "\n",
    "# Save the QC records to a TSV file\n",
    "qc_output_path_rct = \"follow-up_qc_rct_DCC_data_release_v2-0-0.tsv\"\n",
    "df_qc_rct = pd.DataFrame(qc_records_rct)\n",
    "df_qc_rct.to_csv(qc_output_path_rct, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "# Save the cleaned df_output to a TSV file\n",
    "output_path_rct = \"follow-up_rct_DCC_data_release_v2-0-0.tsv\"\n",
    "df_output_rct.to_csv(output_path_rct, sep=\"\\t\", index=False, header=True)\n",
    "\n",
    "print(f\"Cleaned RCT follow-up table saved as: {output_path_rct}\")\n",
    "print(f\"RCT QC table saved as: {qc_output_path_rct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce06bc-0613-462b-b4e1-27f204d3df2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
