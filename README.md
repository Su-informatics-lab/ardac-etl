# ardac-etl
ARDaC ETL (Extract Transform Load) workflows for DCC data release version 2.0.0.  Currently, the workflows transform observational and clinical data stored in CSV files, to ARDaC node files in TSV format.

# Installation
The python workflow is implemented and tested with python 3.13.2.  Furthermore, the NextFlow workflow scripts
utilize Anaconda Python virtual environments.  Anaconda is chosen over the Python built-in virtual environment
manager because NextFlow has a strong preference for using Anaconda virtual environments.

If Anaconda is not already installed on your system, the small-scale Anaconda environment manager called
_miniconda_ can be installed easily using the following [installation instructions](https://www.anaconda.com/docs/getting-started/miniconda/install#macos-linux-installation)

The Anaconda base installation should be availble in your shell's search path after installation.  Open a new
terminal window so that you are using the updated environment.

To show your current search path:
```
echo $PATH
```

The path should contain the installtion location of Anaconda.  If not, you should seek help installing Anaconda
from from your system administrator.

The next task is to create the virtual environment using Anaconda.

## Create the virtual environment
- If `base` environment is not activated, do `conda activate base`. If you are in another virtual environment, then deactivate it first.
- `cd /path/to/ardac-etl/python`
- `conda env create -p ../venv -f conda.yml` creates a virtual environment at `/path/to/project/ardac-etl/venv` with packages and python installed accoridng to `conda.yml` 

The created Python virtual environment at `/path/to/project/ardac-etl/venv` should be used for development of the
ardac-etl project and used with the NextFlow workflow.  If you are using VSCode as your IDE, you should set the
following configuration fields in the VSCode settings accordingly:
```
Python: Venv Path = ./venv
Python: Conda Path = /path/to/your/conda/bin/conda
```

You may also need to set `Python: Locator = js` if the IDE cycles indefinitely on `Reactivating Terminals`.

## Installing NextFlow
Follow the instructions [here](https://www.nextflow.io/docs/latest/install.html) to install NextFlow

# The ARDaC mapper workflow
The mapper workflow is responsible for tranforming the observational and clinical data stored in CSV format to ARDaC node files which conform to the ARDaC common data model (CDM).

## Configuring the ARDaC mapper workflow
The ARDaC mapper workflow is implemented using python scripts to generate the individual node files, and a NextFlow script which is used to manage the execution of the python scripts and manage any dependencies needed by each python process.  The workflow can be configured to read the input and write the output from and to a file system approved for sensitive clinical data.  The workflow can also be configured to store any intermediate data generated by the workflow on the same approved file system.  Logs for each process in the workflow are also created on the approved file system, to reduce chance of spilling sensitive information to an unapproved file system.

The workflow configuration is set by the `nextflow.config` file.  A template is provided by `nextflow.config.template`.  In this configuration file you may specify the location of the input observational and clinical data and the output directory which contains the ARDaC CDM nodes and process log files.

The input directory, given by the parameter `params.input_directory` which must specify the full path, must contain three subdirectories: one given by the parameter `params.obs_input_directory` containing the observational data, one give by `params.rct_input_directory` containing the clinical data, and one given by the parameter `params.node_templates_directory` containing the ARDaC node template TSV file.  The output directory, given by the parameter `params.output_directory` which must specify the full path, must contain a node subdirectory given by `params.ardac_nodes_directory` where the ARDaC node files generated by the workflow will be saved.  Detailed comments are provided for each parameter in the configuration file.

## Running the ARDaC mapper workflow
The NextFlow workflow to generate the ARDaC nodes from the observational and clinical data sets is performed by the `run_observational_workflow.bash` and `run_clinical_workflow.bash` scripts in the `nextflow` subdirectory.  These scripts can be run directly in that same subdirectory.  A hidden log file `.nextflow.log` will be generated describing the run and any problems that may have occurred.

## Workflow versioning
The python scripts perform the mapping from the observational and clinical Data Coordinating Center (DCC) format to the ARDaC CDM node format.  The DCC format currently supported by the mappers is set in the `_constants.py` file in the `python/ardac` script directory under the parameter `__dcc_data_release__`.  The parameter `__mapping_version__` sets the version of the mapping software which implements the mapping for the current DCC release.  If the mapping for a particular DCC data release is to be updated, then the mapping version should be increased.  If support for a new DCC data release is to be implemented, then the DCC release version should be increased and the mapping version reset to `1.0.0`.

The NextFlow workflow script is built for a particular DCC data release.  The DCC data release version exepected by the NextFlow workflow is set in the `nextflow.config` file under the `params.dcc_release` configuration parameter.

# Git branch management
The `main` branch is expected to contain the latest tested mapping implementation for production use. Git tags should be used to indicate which main branch version corresponds to a particular DCC release and mapping version.  Development for a new mapping version should occur in the `develop` branch.  Any development of new features should occur in subbranches of the `develop` branch and merged into the `develop` branch as they are completed.  The `develop` branch should also be used for integration of multiple new features through merging of the feature branches into `develop`.  Once the `develop` branch is fully tested, the version parameters can be updated accordingly and the branch merged into `main` and tagged for prodcution release. 



