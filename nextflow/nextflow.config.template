//
// Pipeline parameters
//

params {
   // DEBUG, INFO, WARN, ERROR are possible NextFlow log levels set by the
   // NextFlow command line option `-log-file`.  Use log.debug, log.info,
   // log.warn, and log.error commands in workflow functions.

   // Log level for all python scripts: DEBUG, INFO, WARNING, ERROR, CRITICAL
   python_log_level = "DEBUG"

   // Expected version of data mapping tools to use
   dcc_release = "DCC_data_release_v2.0.0"

   // Path to the top level of the ARDaC ETL project
   ardac_etl_path = "/path/to/ardac-etl"

   // Path to the Python scripts
   ardac_mapper_scripts = "${params.ardac_etl_path}/python/ardac"

   // Full path to input base directory
   input_directory = "/path/to/dcc_v2.0.0_data"

   // ARDaC node templates directory
   node_templates_directory = "node_templates"

   // Observational data input subdirectory
   obs_input_directory = "obs_data"

   // Clinical data input subdirectory
   rct_input_directory = "rct_data"
   
   // Full path to output base directory
   output_directory = "/path/to/nextflow_output"

   // Output subdirectory for generated ARDaC node files
   ardac_nodes_directory = "ardac_nodes"

   // Subjects input files
   observational_subjects_csv_file = "OBS_SUBJECTS.csv"
   clinical_subjects_csv_file = "RCT_SUBJECTS.csv"
   
   // Liver scores input files
   observational_liver_scores_csv_file = "OBS_LIVERSCORES.csv"
   clinical_liver_scores_csv_file = "RCT_LIVERSCORES.csv"

   // Medical information files
   observational_med_info_csv_file = "OBS_MEDINFO.csv"
   clinical_med_info_csv_file = "RCT_MEDINFO.csv"

   // Vitals files
   observational_vitals_csv_file = "OBS_VITALS.csv"
   clinical_vitals_csv_file = "RCT_VITALS.csv"

   // SOC files
   observational_soc_csv_file = "OBS_SOC.csv"
   clinical_soc_csv_file = "RCT_SOC.csv"

   // Audit files
   observational_audit_csv_file = "OBS_AUDIT.csv"
   clinical_audit_csv_file = "RCT_AUDIT.csv"
}

workDir = "${params.output_directory}/nextflow_work"

profiles {
   conda {
      conda.enabled = true
      process.conda = "${params.ardac_etl_path}/venv"
   }

   workstation {
      process.executor = 'local'
   }

   hpc_cluster {
      process.executor = 'slurm'
      process.resourceLimits = [
         memory: 4.GB,
         cpus: 1,
         time: 2.h,
      ]
   }
}

process {
   beforeScript = "export PYTHONPATH=${params.ardac_mapper_scripts}"
   // defaults for all processes
   cpus = 1
   memory = 2.GB
   // allocations for a specific process
    //withName: 'PROCESS_NAME' {
    //    cpus = 4
    //}
}
